[{"authors":["shivam-thukral"],"categories":null,"content":"My primary research focus revolves around deep learning algorithms and their integration into robotic systems to enhance their intelligence, physical consistency, and seamless interaction with human counterparts. As a Senior Software Engineer specializing in Machine Learning and Robotics at Locus Robotics, I actively contribute to the advancement of autonomous mobile robots, enabling them to perceive their surroundings and make intelligent decisions.\nI recently completed my Master of Science degree in Computer Science from the University of British Columbia, under the supervision of Ian M. Mitchell. Before enrolling at UBC, I was a research fellow at TCS Research and Innovation Labs, where I contributed to the automation of warehouse robotics under the guidance of Swagat Kumar and Rajesh Sinha. Additionally, I hold a Bachelor\u0026rsquo;s degree in Computer Science from IIIT Delhi, where I worked under the supervision of Rahul Purandare and closely collaborated with P.B. Sujit.\nMy experience and expertise lie in pushing the boundaries of what is possible with machine learning in the field of robotics, continuously striving to create systems that are not only autonomous but also capable of sophisticated interaction and collaboration with humans.\n","date":1746057600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1746057600,"objectID":"798c9715f63a0d7ad1a28714a2d3ded2","permalink":"/author/shivam-thukral/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shivam-thukral/","section":"authors","summary":"My primary research focus revolves around deep learning algorithms and their integration into robotic systems to enhance their intelligence, physical consistency, and seamless interaction with human counterparts. As a Senior Software Engineer specializing in Machine Learning and Robotics at Locus Robotics, I actively contribute to the advancement of autonomous mobile robots, enabling them to perceive their surroundings and make intelligent decisions.","tags":null,"title":"Shivam Thukral","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"42bc04c138a3c5b43479eff9fa12bf11","permalink":"/home-unused/slider/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/slider/","section":"home-unused","summary":"","tags":null,"title":"","type":"home-unused"},{"authors":null,"categories":null,"content":"The Best Way to Create the Website You Want from Markdown (or Jupyter/RStudio)\nBuild Anything with Widgets\nStar\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ff3af16109a08648bdce10d3973de99c","permalink":"/home-unused/hero/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/hero/","section":"home-unused","summary":"The Best Way to Create the Website You Want from Markdown (or Jupyter/RStudio)\nBuild Anything with Widgets\nStar","tags":null,"title":"Academic","type":"home-unused"},{"authors":null,"categories":null,"content":"Welcome to the Academic Kickstart template!\nFollow our Getting Started and Page Builder guides to easily personalize the template and then add your own content.\nFor inspiration, check out the Markdown files which power the personal demo. The easiest way to publish your new site to the internet is with Netlify.\n  View the documentation  Ask a question  Request a feature or report a bug Updating? View the Update Guide and Release Notes Support development of Academic:   Donate a coffee  Become a backer on Patreon  Decorate your laptop or journal with an Academic sticker  Wear the T-shirt     This homepage section is an example of adding elements to the Blank widget.\nBackgrounds can be applied to any section. Here, the background option is set give a color gradient.\nTo remove this section, delete content/home/demo.md.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1d1825344e8f4b25c2137e0a9c8b655f","permalink":"/home-unused/demo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/demo/","section":"home-unused","summary":"Welcome to the Academic Kickstart template!\nFollow our Getting Started and Page Builder guides to easily personalize the template and then add your own content.\nFor inspiration, check out the Markdown files which power the personal demo.","tags":null,"title":"Academic Kickstart","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"4a7e3501655fed0a4b0ce814e15ff2c9","permalink":"/home-unused/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/skills/","section":"home-unused","summary":"","tags":null,"title":"Skills","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9e909a8894fd21a2eff4b3e43238d81e","permalink":"/home-unused/accomplishments/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/accomplishments/","section":"home-unused","summary":"","tags":null,"title":"Accomplish\u0026shy;ments","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0e643989bdefe366f2b5fddf949a36b6","permalink":"/home-unused/posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/posts/","section":"home-unused","summary":"","tags":null,"title":"Recent Posts","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"b3f45f4a1c65dae9e5e30f53b9f83edd","permalink":"/home-unused/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/people/","section":"home-unused","summary":"","tags":null,"title":"Meet the Team","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"28f54f6e819207239a6024bbaa9d78de","permalink":"/home-unused/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/featured/","section":"home-unused","summary":"","tags":null,"title":"Featured Publications","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"657179738bed56748434d6ae76e8a647","permalink":"/home-unused/tags/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/home-unused/tags/","section":"home-unused","summary":"","tags":null,"title":"Popular Topics","type":"home-unused"},{"authors":null,"categories":null,"content":"","date":1747267200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747267200,"objectID":"ba19fab05dbcf16829041615195e303a","permalink":"/project/ddpm/","publishdate":"2025-05-15T00:00:00Z","relpermalink":"/project/ddpm/","section":"project","summary":"DDPM are generative models that learn to transform Gaussian noise into data samples by iteratively denoising through a Markovian diffusion process. The model is trained on CIFAR10.","tags":["AI","Vision"],"title":"Diffusion Model","type":"project"},{"authors":null,"categories":null,"content":"","date":1747180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747180800,"objectID":"78f5ec6fb77b38fc2755985d7264bfb0","permalink":"/project/cgan/","publishdate":"2025-05-14T00:00:00Z","relpermalink":"/project/cgan/","section":"project","summary":"Generative Adversarial Networks (GANs) consist of a generator and a discriminator trained in a competitive framework. This implementation is trained on the CelebA dataset and conditioned on attributes such as 'Male' and 'Blond Hair' to generate realistic face images.","tags":["AI","Vision"],"title":"Conditional GAN","type":"project"},{"authors":null,"categories":null,"content":"","date":1747008000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747008000,"objectID":"f6cd2a92a2eb0905f6d025c0ef9dafc4","permalink":"/project/vit/","publishdate":"2025-05-12T00:00:00Z","relpermalink":"/project/vit/","section":"project","summary":"Demonstration of Vision Transformers applied to the CIFAR-10 dataset for classification.","tags":["AI","Vision"],"title":"Classification with Vision Transformers","type":"project"},{"authors":null,"categories":null,"content":"","date":1746921600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746921600,"objectID":"352df8a81fb5f2c35e95ec9232776e79","permalink":"/project/yolo/","publishdate":"2025-05-11T00:00:00Z","relpermalink":"/project/yolo/","section":"project","summary":"YOLO model trained on the Pascal VOC dataset through transfer learning techniques.","tags":["AI","Vision"],"title":"Yolo Object Detector","type":"project"},{"authors":null,"categories":null,"content":"","date":1746662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746662400,"objectID":"5e1ad859cd0a1e9d59a010e5f8f0581f","permalink":"/project/clip/","publishdate":"2025-05-08T00:00:00Z","relpermalink":"/project/clip/","section":"project","summary":"A multimodal model by OpenAI that learns visual concepts from natural language supervision, enabling it to understand and relate images and text efficiently.","tags":["AI","Vision"],"title":"CLIP Classifcation","type":"project"},{"authors":["Aniruddha Singhal","Harshad Khadilkar","Venkat Raju Chintalapalli Patta","Deepak Raina","Venkatesh Srinivas Prasad","Shivam Thukral","Rajesh Sinha","Richa Verma"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --  ","date":1746057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746057600,"objectID":"00752ad9f63c923c6e44a553354387c5","permalink":"/publication/palletiser-us/","publishdate":"2025-05-20T00:00:00Z","relpermalink":"/publication/palletiser-us/","section":"publication","summary":"State of the art automated bin packing systems fail to handle dynamic scenarios in which information on dimensions of objects to be loaded is not available in advance. These systems also fail to consider capabilities of robots used for the automated packing of objects/bins. The disclosure herein generally relates to automated bin packing, and, more particularly, to a system and method for autonomous multi-bin parcel loading system. The system handles an online object packing in which information on dimensions of objects to be loaded is not available in advance. The system is also configured to consider capabilities of one or more robots used for loading objects to containers, while generating recommendations for object packing.","tags":["Warehouse Robotics"],"title":"System and Method for Autonomous Multi-bin Parcel Loading System","type":"publication"},{"authors":null,"categories":null,"content":"","date":1742428800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1742428800,"objectID":"2f634557c8b530f2250a8e476a9f616b","permalink":"/project/unet/","publishdate":"2025-03-20T00:00:00Z","relpermalink":"/project/unet/","section":"project","summary":"Training of the UNet architecture on the Oxford-IIIT Pet dataset for accurate image segmentation.","tags":["AI","Vision"],"title":"Semantic Segmentation with UNet","type":"project"},{"authors":null,"categories":null,"content":"","date":1740787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740787200,"objectID":"5edcc52e89a8e41fac95757de813398c","permalink":"/project/alexnet/","publishdate":"2025-03-01T00:00:00Z","relpermalink":"/project/alexnet/","section":"project","summary":"Implementation the AlexNet architecture, the landmark model that won the 2012 ImageNet challenge. It uses the CIFAR-10 dataset for training and integrates TensorBoard for real-time visualization of metrics.","tags":["AI","Vision"],"title":"AlexNet","type":"project"},{"authors":null,"categories":null,"content":"","date":1735776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735776000,"objectID":"cdf10a74509a6058abdd21d5a06b37ff","permalink":"/project/resnet-18/","publishdate":"2025-01-02T00:00:00Z","relpermalink":"/project/resnet-18/","section":"project","summary":"ResNet18 trained from scratch on the CIFAR-10 dataset.","tags":["AI","Vision"],"title":"ResNet-18","type":"project"},{"authors":null,"categories":null,"content":"","date":1735776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735776000,"objectID":"1d0cf9b0cb754d046735fa5edb0a707b","permalink":"/project/stn/","publishdate":"2025-01-02T00:00:00Z","relpermalink":"/project/stn/","section":"project","summary":"Spatial Transformer Networks allow a neural network to learn how to perform spatial transformations on the input image in order to enhance the geometric invariance of the model.","tags":["AI","Vision"],"title":"Spatial Transform Networks","type":"project"},{"authors":null,"categories":null,"content":"","date":1735776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735776000,"objectID":"9474b73bf57816e8bcdbc05026ab4f44","permalink":"/project/vgg16/","publishdate":"2025-01-02T00:00:00Z","relpermalink":"/project/vgg16/","section":"project","summary":"Built on the 2014 ImageNet Challenge winner, this project explores transfer learning for efficient adaptation.","tags":["AI","Vision"],"title":"Transfer learning with VGG16","type":"project"},{"authors":null,"categories":null,"content":"","date":1735689600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735689600,"objectID":"78dae03b78899ba27614be7b3e1984ae","permalink":"/project/mae_vs_moco/","publishdate":"2025-01-01T00:00:00Z","relpermalink":"/project/mae_vs_moco/","section":"project","summary":"A comparison between MoCo and MAE embeddings generate from CIFAR10 dataset.","tags":["AI","Vision"],"title":"MAE vs MOCO Embedding","type":"project"},{"authors":["Shivam Thukral"],"categories":null,"content":"","date":1707955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707955200,"objectID":"466ecb67f4254b05a62755af00604c56","permalink":"/talk/locus-learning/","publishdate":"2024-02-15T00:00:00Z","relpermalink":"/talk/locus-learning/","section":"talk","summary":"Developed an object detector to detect objects in warehouse environments.","tags":[],"title":"Locus Learning : Object Detection","type":"talk"},{"authors":["Shivam Thukral"],"categories":null,"content":"","date":1686787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686787200,"objectID":"ce7edd8f68a14aeef8828c64aee833f3","permalink":"/talk/negative-obstacle-detection/","publishdate":"2023-06-15T00:00:00Z","relpermalink":"/talk/negative-obstacle-detection/","section":"talk","summary":"Proposed a method to detect negative obstacles for locus bots.","tags":[],"title":"Negative Obstacle Detection for LocusBots","type":"talk"},{"authors":["Shivam Thukral"],"categories":null,"content":"","date":1642204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642204800,"objectID":"dae3fb42ae3d8bc92ed4601a401f3278","permalink":"/talk/approachfinder/","publishdate":"2022-01-15T00:00:00Z","relpermalink":"/talk/approachfinder/","section":"talk","summary":"Thesis Project Presentation","tags":[],"title":"ApproachFinder: Real-time Perception of Potential Docking Locations for Smart Wheelchairs","type":"talk"},{"authors":null,"categories":null,"content":"","date":1633392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633392000,"objectID":"201089aa09fc8a2239f97d06329c2d8f","permalink":"/project/approachfinder-nn/","publishdate":"2021-10-05T00:00:00Z","relpermalink":"/project/approachfinder-nn/","section":"project","summary":"Developed an end-to-end docking location detection network based on synergy of deep point set networks and Hough voting. ","tags":["ROS","AI","Vision","Thesis"],"title":"ApproachFinder-NN","type":"project"},{"authors":null,"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"c751cb15c2842afcfce31022732ea9cb","permalink":"/project/approachfinder_cv/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/project/approachfinder_cv/","section":"project","summary":"Developed a real-time computer vision pipeline to find potential docking locations indoor environments for wheelchairs using point cloud data.","tags":["ROS","AI","Vision","Thesis"],"title":"ApproachFinder-CV","type":"project"},{"authors":null,"categories":null,"content":"","date":1627776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627776000,"objectID":"5de93647f0f19d124d71a7360b26525d","permalink":"/project/shared_control/","publishdate":"2021-08-01T00:00:00Z","relpermalink":"/project/shared_control/","section":"project","summary":"Real-time wheelchair navigation with shared control using model predictive path integral (MPPI) controller. ","tags":["ROS","AI","Vision","Thesis"],"title":"Wheelchair Navigation","type":"project"},{"authors":["Shivam Thukral"],"categories":null,"content":"","date":1621036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621036800,"objectID":"3412c102e7b7272a28454d0155271dd2","permalink":"/talk/3d-object-detection/","publishdate":"2021-05-15T00:00:00Z","relpermalink":"/talk/3d-object-detection/","section":"talk","summary":"Compared different state-of-the-art 3D object detection networks","tags":[],"title":"3D Object Detection for Indoor Scenes","type":"talk"},{"authors":null,"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"329e0c3464b4d55edfeffd75f64f83b4","permalink":"/project/ros_votenet/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/project/ros_votenet/","section":"project","summary":"Indoor object detection using Votenet for pointclouds captured from RGB-D cameras in ROS simulation.","tags":["ROS","AI","Vision","Thesis"],"title":"Real-time Indoor Object Detection","type":"project"},{"authors":null,"categories":null,"content":"","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"ff581fd8d70e0d103658023acf934a61","permalink":"/project/visual_servoing/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/project/visual_servoing/","section":"project","summary":"Image-based visual servoing in eye-in-hand configuration for Universal Robot 5 using Microsoft Kinect V2 camera.","tags":["ROS","Vision"],"title":"Visual Servoing","type":"project"},{"authors":["Shivam Thukral"],"categories":null,"content":"","date":1607385600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607385600,"objectID":"1f59868dc014417f12162def6c697479","permalink":"/talk/visual-servoing/","publishdate":"2020-12-08T00:00:00Z","relpermalink":"/talk/visual-servoing/","section":"talk","summary":"Image-based visual servoing using industrial manipulators","tags":[],"title":"Visual Servoing using Industrial Manipulator","type":"talk"},{"authors":["Àngel Santamaria-Navarro","Juan Andrade-Cetto"],"categories":null,"content":"","date":1606435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606435200,"objectID":"557fab7d40e87ee803c7bd3bb811d1dc","permalink":"/talk/ibvs/","publishdate":"2020-11-27T00:00:00Z","relpermalink":"/talk/ibvs/","section":"talk","summary":"IBVS without knowing camera parameters.","tags":[],"title":"Uncalibrated image-based visual servoing","type":"talk"},{"authors":["Wesley H. Huang","Brett R. Fajen","Jonathan R. Finka","William H. Warren"],"categories":null,"content":"","date":1597881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597881600,"objectID":"54d5db59b4461872747da4eb995c031c","permalink":"/talk/potential-functions/","publishdate":"2020-08-20T00:00:00Z","relpermalink":"/talk/potential-functions/","section":"talk","summary":"Design a real-time local navigations system, based upon a model of human navigation","tags":[],"title":"Visual navigation and obstacle avoidance using a steering potential function","type":"talk"},{"authors":["Quang-Hieu Pham","Binh-Son Hua","Duc Thanh Nguyen","Sai-Kit Yeung"],"categories":null,"content":"","date":1592179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592179200,"objectID":"6fd3c2543b063da62beb34988938d40c","permalink":"/talk/3d-semantic-segmentation/","publishdate":"2020-06-15T00:00:00Z","relpermalink":"/talk/3d-semantic-segmentation/","section":"talk","summary":"On-the-fly 3D indoor semantic segmentation of indoor scenes","tags":[],"title":"Real-time Progressive 3D Semantic Segmentation for Indoor Scenes","type":"talk"},{"authors":["Aniruddha Singhal","Ayush Kumar","Shivam Thukral","Deepak Raina","Swagat Kumar"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --  ","date":1590969600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590969600,"objectID":"b1bcc8ccbb1b97baaff0563558f24da8","permalink":"/publication/conference-paper-chitrakar/","publishdate":"2020-06-01T00:00:00Z","relpermalink":"/publication/conference-paper-chitrakar/","section":"publication","summary":"This paper presents a robotic system Chitrakar which autonomously converts any image of a human face to a recognizable non-self-intersecting loop (Jordan Curve) and draws it on any planar surface. The image is processed using Mask R-CNN for instance segmentation, Laplacian of Gaussian (LoG) for feature enhancement and intensity-based probabilistic stippling for the image to points conversion. These points are treated as a destination for a travelling salesman and are connected with an optimal path which is calculated heuristically by minimizing the total distance to be travelled. This path is converted to a Jordan Curve in feasible time by removing intersections using a combination of image processing, 2-opt, and Bresenham's Algorithm. The robotic system generates n instances of each image for human aesthetic judgement, out of which the most appealing instance is selected for the final drawing. The drawing is executed carefully by the robot's arm using trapezoidal velocity profiles for jerk-free and fast motion. The drawing, with a decent resolution, can be completed in less than 30 minutes which is impossible to do by hand. This work demonstrates the use of robotics to augment humans in executing difficult craft-work instead of replacing them altogether.","tags":["Robot art","Image processing","Jordan curve","Aesthetics","Human face portrait"],"title":"Chitrakar: Robotic System for Drawing Jordan Curve of Facial Portrait","type":"publication"},{"authors":null,"categories":null,"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"85f281820e2756740a88203a21e595c3","permalink":"/project/chess/","publishdate":"2020-03-01T00:00:00Z","relpermalink":"/project/chess/","section":"project","summary":"Developed a predictive model that can play chess like humans, with special focus on modelling amateur play.","tags":["AI"],"title":"Modelling-Human-Behaviour-in-Chess","type":"project"},{"authors":null,"categories":null,"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"6fc5b9c4bef317d6732fce445b0d7b89","permalink":"/project/verifying_dnn/","publishdate":"2020-03-01T00:00:00Z","relpermalink":"/project/verifying_dnn/","section":"project","summary":"Summarised 10 state-of-the-art approaches to verify DNN and developed a framework to test networks (eg ACAS Xu) on safety cases using SMT solvers.","tags":["AI","Verification"],"title":"Verifying DNN","type":"project"},{"authors":["Rony Goldenthal","David Harmon","Raanan Fattal","Michel Bercovier","Eitan Grinspun"],"categories":null,"content":"","date":1571184000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571184000,"objectID":"23a63c1083897060fa5e04d5a01641b8","permalink":"/talk/cloth-simulation/","publishdate":"2019-10-16T00:00:00Z","relpermalink":"/talk/cloth-simulation/","section":"talk","summary":"Cloth Simulation","tags":[],"title":"Efficient Simulation of Inextensible Cloth","type":"talk"},{"authors":null,"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"d19f3170e380740ba14f80eacde5baa9","permalink":"/project/3d_pose/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/project/3d_pose/","section":"project","summary":"Developed a CNN capable of obtaining a temporally consistent, full 3D skeletal human pose from a single RGB camera.","tags":["AI","Vision"],"title":"3D Human Pose Estimation","type":"project"},{"authors":null,"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"f651dc2f727eea1dab0d0e96d36b69d3","permalink":"/project/bugflood/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/project/bugflood/","section":"project","summary":"Developed an optimal path planning algorithm in obstacle rich environments. BugFlood unlike its predecessor uses a split and kill approach to advance in the environment. Performance of this algorithm was compared with different planners from Open Motion Planning Library (OMPL) and visibility graph methods.","tags":["ROS"],"title":"BugFlood","type":"project"},{"authors":["Nishant Sharma","Shivam Thukral","Sandip Aine","P.B. Sujit"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). --  ","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"d0de70116ef593be029d5c50e30a16d5","permalink":"/publication/conference-paper-acc/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/conference-paper-acc/","section":"publication","summary":"We present a path planning technique inspired by the bug algorithm to quickly compute paths in an obstacle rich environment (or to report that no such path exists). In our approach, we simulate virtual bugs that upon sensing an obstacle splits into two bugs exploring the obstacle boundary in opposite directions, until the bugs find the goal in the line-ofsight. Then the bug leaves the obstacle and proceeds towards the goal. The process of splitting a bug into two continues until all the bugs reach the goal. The algorithm is simple to implement and it rapidly finds a solution if one exists. We provide worst case bounds on the path length with provable guarantees on convergence and develop heuristics to minimize the number of active bugs in the environment. We compare the performance of our algorithm with different planners from Open Motion Planning Library (OMPL) and visibility graph methods. The results show that the proposed algorithm delivers lower cost paths compared to other planners with lower computational time and rapidly indicates if a path does not exist.","tags":null,"title":"A virtual bug planning technique for 2D robot path planning","type":"publication"}]